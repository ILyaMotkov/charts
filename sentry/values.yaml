global:
  storageClass: sentry20
  volumePermissions:
    enabled: true


prefix:

user:
  create: true
  email: admin@sentry.local
  password: aaaa

images:
  sentry:
    imagePullSecrets:
      - name: harbor
    repository: dc2.srvhub.tools/tools/getsentry
    tag: 20.8.1
    pullPolicy: IfNotPresent
    # imagePullSecrets: []
  snuba:
    #    repository: getsentry/snuba
    #    tag: 20.8.0
    #    pullPolicy: IfNotPresent
    imagePullSecrets: []
  relay:
    #    repository: getsentry/relay
    #    tag: 20.8.0
    #    pullPolicy: IfNotPresent
    imagePullSecrets: []
  exim:
    imagePullSecrets:
      - name: harbor
    repository: dc2.srvhub.tools/tools/exim-sentry
    pullPolicy: IfNotPresent

relay:
  mode: proxy
  replicas: 1
  env: []
  probeInitialDelaySeconds: 10
  resources: {}
  affinity: {}
  nodeSelector: {}
  # tolerations: []
  # podLabels: []

  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 50

sentry:
  singleOrganization: true
  web:
    replicas: 1
    env: []
    probeInitialDelaySeconds: 10
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

    autoscaling:
      enabled: false
      minReplicas: 2
      maxReplicas: 5
      targetCPUUtilizationPercentage: 50

  worker:
    replicas: 2
    # concurrency: 4
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

    # it's better to use prometheus adapter and scale based on
    # the size of the rabbitmq queue
    autoscaling:
      enabled: false
      minReplicas: 2
      maxReplicas: 5
      targetCPUUtilizationPercentage: 50

  ingestConsumer:
    replicas: 1
    # concurrency: 4
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

    # it's better to use prometheus adapter and scale based on
    # the size of the rabbitmq queue
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 3
      targetCPUUtilizationPercentage: 50

  cron:
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []
  postProcessForward:
    replicas: 1
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []
    # commitBatchSize: 1
  cleanup:
    enabled: true
    schedule: "0 0 * * *"
    days: 90

snuba:
  api:
    replicas: 1
    env: []
    probeInitialDelaySeconds: 10
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

    autoscaling:
      enabled: false
      minReplicas: 2
      maxReplicas: 5
      targetCPUUtilizationPercentage: 50

  consumer:
    replicas: 1
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

  outcomesConsumer:
    replicas: 1
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

  sessionsConsumer:
    replicas: 1
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

  transactionsConsumer:
    replicas: 1
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

  replacer:
    env: []
    resources: {}
    affinity: {}
    nodeSelector: {}
    # tolerations: []
    # podLabels: []

  dbInitJob:
    env: []

  migrateJob:
    env: []


hooks:
  enabled: true
  dbInit:
    env: []
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 300m
        memory: 2048Mi
  snubaInit:
    resources:
      limits:
        cpu: 2000m
        memory: 1Gi
      requests:
        cpu: 700m
        memory: 1Gi
system:
  url: ""
  adminEmail: ""
  ## This should only be used if you’re installing Sentry behind your company’s firewall.
  public: false
  ## This will generate one for you (it's must be given upon updates)
  #secretKey: "xx"

mail:
  backend: smtp # smtp
  useTls: no
  username:
  password:
  port: 25
  host: smtp
  from: developer@srvhub.ru

exim:
  smtpHost: mail.srvhub.ru
  smtpPassword: id~NU9#9
  smtpPort: 587
  smtpUser: developer@srvhub.ru

symbolicator:
  enabled: false

transaction_events:
  force_disable_internal_project: true

auth:
  register: true

service:
  name: sentry
  type: ClusterIP
  externalPort: 9000
  annotations: {}
  # externalIPs:
  # - 192.168.0.1
  # loadBalancerSourceRanges: []

github: {} # https://github.com/settings/apps (Create a Github App)
# github:
#   appId: "xxxx"
#   appName: MyAppName
#   clientId: "xxxxx"
#   clientSecret: "xxxxx"
#   privateKey: "-----BEGIN RSA PRIVATE KEY-----\nMIIEpA" !!!! Don't forget a trailing \n
#   webhookSecret:  "xxxxx`"

githubSso: {} # https://github.com/settings/developers (Create a OAuth App)
  # clientId: "xx"
# clientSecret: "xx"

slack: {}
# slack:
#   clientId:
#   clientSecret:
#   verificationToken:
#   # channels.* of Slack API is deprecated.
#   # All new slack apps created after June 10th, 2020 will give error,
#   # you need to specify `False` if you want to use the Slack App created after that.
#   # ref : https://github.com/getsentry/sentry/pull/19446
#   legacyApp:

nginx:
  enabled: true
  containerPort: 8080
  existingServerBlockConfigmap: sentry-nginx
  resources: {}
  replicaCount: 1
  service:
    type: ClusterIP
    port: 80

ingress:
  enabled: false
  # annotations:
  #   kubernetes.io/tls-acme:
  #   certmanager.k8s.io/issuer:
  #
  #   nginx.ingress.kubernetes.io/proxy-body-size:
  #   nginx.ingress.kubernetes.io/use-regex: "true"
  #
  #   nginx.ingress.kubernetes.io/enable-cors: "true"
  #   nginx.ingress.kubernetes.io/cors-allow-methods: "PUT,GET,POST,OPTIONS"
  #   nginx.ingress.kubernetes.io/cors-allow-origin: "*"
  #   nginx.ingress.kubernetes.io/cors-allow-credentials: "true"
  #
  # hostname:
  #
  # tls:
  # - secretName:
  #   hosts:

filestore:
  # Set to one of filesystem, gcs or s3 as supported by Sentry.
  backend: filesystem

  filesystem:
    path: /var/lib/sentry/files

    ## Enable persistence using Persistent Volume Claims
    ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      enabled: true
      ## database data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass: "sentry20"
      accessMode: ReadWriteOnce
      size: 10Gi
      eximsize: 3Gi

  dsym:
    cache:
      path: /var/lib/sentry/dsym-cache

  releasefile:
    cache:
      path: /var/lib/sentry/releasefile-cache

      ## Whether to mount the persistent volume to the Sentry worker and
      ## cron deployments. This setting needs to be enabled for some advanced
      ## Sentry features, such as private source maps. If you disable this
      ## setting, the Sentry workers will not have access to artifacts you upload
      ## through the web deployment.
      ## Please note that you may need to change your accessMode to ReadWriteMany
      ## if you plan on having the web, worker and cron deployments run on
      ## different nodes.
      persistentWorkers: false

  ## Point this at a pre-configured secret containing a service account. The resulting
  ## secret will be mounted at /var/run/secrets/google
  gcs:
  # credentialsFile: credentials.json
  #  secretName:
  #  bucketName:

  ## Currently unconfigured and changing this has no impact on the template configuration.
  s3: {}
  #  accessKey:
  #  secretKey:
  #  bucketName:
  #  endpointUrl:
  #  signature_version:
  #  region_name:
  #  default_acl:

config:
  configYml: |
    # No YAML Extension Config Given
  sentryConfPy: |
    #######################
    # Кастомные настройки #
    #######################

    SENTRY_DEFAULT_TIME_ZONE = 'Europe/Moscow'

    SENTRY_SINGLE_ORGANIZATION = False

    SENTRY_OPTIONS.update({
        'system.secret-key': env('SENTRY_SECRET_KEY'),
        'mail.from': env('SENTRY_MAIL_FROM') or 'root@localhost',
    })

    if env('SENTRY_USE_LDAP', False):
        import ldap
        from django_auth_ldap.config import LDAPSearch, ActiveDirectoryGroupType

        SENTRY_FEATURES.update({
            'auth:register': False,
            'organizations:sso-basic': False,
            'organizations:sso-saml2': False,
            'organizations:sso-rippling': False,
        })

        SENTRY_MANAGED_USER_FIELDS = ('name', 'email')

        AUTHENTICATION_BACKENDS = (
            'sentry_ldap_auth.backend.SentryLDAPBackend',
        )

        AUTH_LDAP_SERVER_URI = env('LDAP_SERVER_URI')
        AUTH_LDAP_BIND_DN = env('LDAP_BIND_DN')
        AUTH_LDAP_BIND_PASSWORD = env('LDAP_BIND_PASSWORD')

        AUTH_LDAP_USER_SEARCH = LDAPSearch(
            env('LDAP_USER_BASE_DN'),
            ldap.SCOPE_SUBTREE,
            env('LDAP_USER_FILTER') or '(&(objectClass=person)(sAMAccountName=%(user)s))'
        )

        AUTH_LDAP_GROUP_SEARCH = LDAPSearch(
            env('LDAP_GROUP_BASE_DN'),
            ldap.SCOPE_SUBTREE,
            env('LDAP_GROUP_FILTER') or '(objectClass=group)'
        )

        AUTH_LDAP_GROUP_TYPE = ActiveDirectoryGroupType()

        AUTH_LDAP_USER_STATUS_ATTR = env('LDAP_USER_STATUS_ATTR') or 'userAccountControl'
        AUTH_LDAP_USER_DISABLED_MASK = int(env('LDAP_USER_DISABLED_MASK') or 2)

        AUTH_LDAP_USER_ATTR_MAP = {
            'name': env('LDAP_USER_ATTR_MAP_NAME') or 'displayName',
            'email': env('LDAP_USER_ATTR_MAP_EMAIL') or 'mail',
        }

        AUTH_LDAP_CACHE_TIMEOUT = int(env('LDAP_CACHE_TIMEOUT') or 300)

        AUTH_LDAP_SENTRY_INSTANCE_NAME = env('LDAP_SENTRY_INSTANCE_NAME') or 'Sentry'
        AUTH_LDAP_SENTRY_DEFAULT_ORGANIZATION = env('LDAP_SENTRY_DEFAULT_ORGANIZATION') or 'sentry'
        AUTH_LDAP_SENTRY_ROLES = [
            {
                'group_name': env('LDAP_SENTRY_MEMBERS_GROUP_NAME') or 'Members',
                'role': 'member',
            },
            {
                'group_name': env('LDAP_SENTRY_ADMINS_GROUP_NAME') or 'Admins',
                'role': 'admin',
            },
            {
                'group_name': env('LDAP_SENTRY_MANAGERS_GROUP_NAME') or 'Managers',
                'role': 'manager',
            },
            {
                'group_name': env('LDAP_SENTRY_OWNERS_GROUP_NAME') or 'Owners',
                'role': 'owner',
            },
        ]
        AUTH_LDAP_SENTRY_SUPERUSERS_GROUP_NAME = env('LDAP_SENTRY_SUPERUSERS_GROUP_NAME') or 'Superusers'

        import logging

        LOGGING['disable_existing_loggers'] = False

        for logger_name in ['django_auth_ldap', 'sentry_auth_ldap']:
            logger = logging.getLogger(logger_name)

            # Встроенный в Sentry обработчик логов падает с ошибкой `UnicodeEncodeError`
            # при записи в лог русскоязычных строк.
            logger.propagate = False

            logger.addHandler(logging.StreamHandler())
            logger.setLevel('DEBUG')

  snubaSettingsPy: |
    # No Python Extension Config Given
  relay: |
    # No YAML relay config given

clickhouse:
  enabled: true
  clickhouse:
    imageVersion: "19.17"
    configmap:
      remote_servers:
        internal_replication: true
    persistentVolumeClaim:
      enabled: true
      dataPersistentVolume:
        storageClassName: sentry20
        enabled: true
        accessModes:
          - "ReadWriteOnce"
        storage: "10Gi"

## This value is only used when clickhouse.enabled is set to false
##
externalClickhouse:
  ## Hostname or ip address of external clickhouse
  ##
  host: "clickhouse"
  tcpPort: 9000
  ## Cluster name, can be found in config
  ## (https://clickhouse.tech/docs/en/operations/server-configuration-parameters/settings/#server-settings-remote-servers)
  ## or by executing `select * from system.clusters`
  ##
  # clusterName: test_shard_localhost

kafka:
  enabled: true
  replicaCount: 3
  allowPlaintextListener: true
  defaultReplicationFactor: 3
  offsetsTopicReplicationFactor: 3
  transactionStateLogReplicationFactor: 3
  transactionStateLogMinIsr: 3

  service:
    port: 9092

## This value is only used when kafka.enabled is set to false
##
externalKafka:
  ## Hostname or ip address of external kafka
  ##
  # host: "kafka-confluent"
  port: 9092

redis:
  enabled: true
  nameOverride: sentry-redis
  usePassword: false
  ## Just omit the password field if your redis cluster doesn't use password
  # password: redis
  master:
    persistence:
      enabled: true

## This value is only used when redis.enabled is set to false
##
externalRedis:
  ## Hostname or ip address of external redis cluster
  ##
  # host: "redis"
  port: 6379
  ## Just omit the password field if your redis cluster doesn't use password
  # password: redis

postgresql:
  enabled: true
  nameOverride: sentry-postgresql
  postgresqlUsername: postgres
  postgresqlDatabase: sentry
  postgresqlPassword: 3KDQFSHRwJ
  replication:
    enabled: false
    slaveReplicas: 2
    synchronousCommit: "on"
    numSynchronousReplicas: 1

## This value is only used when postgresql.enabled is set to false
##
externalPostgresql:
  # host: postgres
  port: 5432
  username: postgres
  # password: postgres
  database: sentry
  # sslMode: require

rabbitmq:
  ## If disabled, Redis will be used instead as the broker.
  enabled: true
  forceBoot: true
  replicaCount: 3
  rabbitmqErlangCookie: pHgpy3Q6adTskzAT6bLHCFqFTF7lMxhA
  rabbitmqUsername: guest
  rabbitmqPassword: guest
  nameOverride: ""

  podDisruptionBudget:
    minAvailable: 1

  persistentVolume:
    storageClass: sentry20
    enabled: true
  resources: {}
  # rabbitmqMemoryHighWatermark: 600MB
  # rabbitmqMemoryHighWatermarkType: absolute

  definitions:
    policies: |-
      {
        "name": "ha-all",
        "pattern": "^((?!celeryev.*).)*$",
        "vhost": "/",
        "definition": {
          "ha-mode": "all",
          "ha-sync-mode": "automatic",
          "ha-sync-batch-size": 1
        }
      }

## Prometheus Exporter / Metrics
##
metrics:
  enabled: false

  ## Configure extra options for liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 2
    failureThreshold: 3
    successThreshold: 1
  readinessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 2
    failureThreshold: 3
    successThreshold: 1

  ## Metrics exporter resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: {}
  #   limits:
  #     cpu: 100m
  #     memory: 100Mi
  #   requests:
  #     cpu: 100m
  #     memory: 100Mi

  nodeSelector: {}
  tolerations: []
  affinity: {}
  # schedulerName:
  # Optional extra labels for pod, i.e. redis-client: "true"
  # podLabels: []
  service:
    type: ClusterIP
    labels: {}

  image:
    repository: prom/statsd-exporter
    tag: v0.17.0
    pullPolicy: IfNotPresent

  # Enable this if you're using https://github.com/coreos/prometheus-operator
  serviceMonitor:
    enabled: false
    additionalLabels: {}
    namespace: ""
    namespaceSelector: {}
    # Default: scrape .Release.Namespace only
    # To scrape all, use the following:
    # namespaceSelector:
    #   any: true
    scrapeInterval: 30s
    # honorLabels: true

# LDAP setting
ldapUri: ldap://192.168.0.47:3268
ldapUserBaseDn: OU=Users,OU=IT,DC=srvhub,DC=ru
ldapGroupBaseDn: OU=Services,DC=srvhub,DC=ru
ldapSentryMembersGroupName: Sentry Members
ldapSentryOwnersGroupName: Sentry Owners
ldapBindDn: syncldap@srvhub.ru
ldapBindPassword: SDFDkfLbvbh2015